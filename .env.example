# Copy this file to .env and update with your settings

# ========================
# AMPLIFIER DIRECTORY CONFIGURATION
# ========================

# Main data directory for processed/generated data
# Supports: relative paths (./data), absolute (/var/data), home paths (~/data)
# Default: .data (in repo, git-ignored)
AMPLIFIER_DATA_DIR=.data

# Content source directories (comma-separated list)
# These directories will be scanned for content to process
# Supports: relative, absolute, and home paths
# Default: .data/content (in repo, git-ignored)
AMPLIFIER_CONTENT_DIRS=.data/content

# =============================================================================
# Backend Configuration (Claude Code vs Codex)
# =============================================================================

# Choose which AI backend to use: "claude" or "codex"
# - "claude": Use Claude Code (VS Code extension) with native hooks
# - "codex": Use Codex CLI with MCP servers
# Default: claude (if not set)
AMPLIFIER_BACKEND=claude

# Auto-detect backend if AMPLIFIER_BACKEND not set
# Checks for .claude/ or .codex/ directories and CLI availability
# Default: true
AMPLIFIER_BACKEND_AUTO_DETECT=true

# Path to Claude CLI (optional, auto-detected if not set)
# CLAUDE_CLI_PATH=/usr/local/bin/claude

# Path to Codex CLI (optional, auto-detected if not set)
# CODEX_CLI_PATH=/usr/local/bin/codex

# Codex-specific configuration
# Profile to use when starting Codex (development, ci, review)
CODEX_PROFILE=development

# Session context for Codex initialization
# Used by .codex/tools/session_init.py to load relevant memories
CODEX_SESSION_CONTEXT="Working on project features"

# Session ID for cleanup (usually set automatically by wrapper)
CODEX_SESSION_ID=

# Usage examples:
#
# Claude Code (default):
#   export AMPLIFIER_BACKEND=claude
#   claude  # Start Claude Code normally
#
# Codex:
#   export AMPLIFIER_BACKEND=codex
#   ./amplify-codex.sh  # Use Codex wrapper
#
# Auto-detect:
#   unset AMPLIFIER_BACKEND
#   export AMPLIFIER_BACKEND_AUTO_DETECT=true
#   # Backend will be auto-detected based on available CLIs
#
# Programmatic usage:
#   from amplifier import get_backend
#   backend = get_backend()  # Uses AMPLIFIER_BACKEND env var
#   result = backend.initialize_session("Working on feature X")

# ========================
# MODEL CONFIGURATION
# ========================

# Amplifier model categories (used across the system)
# Fast model for quick operations and smoke tests
AMPLIFIER_MODEL_FAST=claude-3-5-haiku-20241022

# Default model for standard operations
AMPLIFIER_MODEL_DEFAULT=claude-sonnet-4-20250514

# Thinking model for complex reasoning tasks
AMPLIFIER_MODEL_THINKING=claude-opus-4-1-20250805

# Legacy model configuration (being phased out)
# Fast model for document classification (Haiku is efficient)
KNOWLEDGE_MINING_MODEL=claude-3-5-haiku-20241022

# Powerful model for knowledge extraction (Sonnet for depth)
KNOWLEDGE_MINING_EXTRACTION_MODEL=claude-sonnet-4-20250514

# ========================
# CONTENT PROCESSING
# ========================

# Maximum characters to process from a document (~8000 words)
KNOWLEDGE_MINING_MAX_CHARS=50000

# Characters to use for document classification (fast preview)
KNOWLEDGE_MINING_CLASSIFICATION_CHARS=1500

# ========================
# STORAGE CONFIGURATION
# ========================

# Default document type when classification fails
# Options: article, api_docs, meeting, blog, tutorial, research,
#          changelog, readme, specification, conversation,
#          code_review, post_mortem, general
KNOWLEDGE_MINING_DEFAULT_DOC_TYPE=general

# ========================
# OPTIONAL CONFIGURATION
# ========================

# API Keys (optional - Claude Code SDK may provide these)
# ANTHROPIC_API_KEY=your_api_key_here
# OPENAI_API_KEY=your_openai_api_key_here

# Enable debug output
DEBUG=false

# ========================
# MEMORY SYSTEM
# ========================

# Enable/disable memory system (works with both backends)
# - Claude Code: Uses native hooks for automatic session management
# - Codex: Uses MCP servers for manual tool invocation
# - Used by both .claude/tools/ hooks and .codex/mcp_servers/
# Default: true
MEMORY_SYSTEM_ENABLED=true

# Model for memory extraction (fast, efficient model recommended)
MEMORY_EXTRACTION_MODEL=claude-3-5-haiku-20241022

# Memory extraction timeout in seconds
MEMORY_EXTRACTION_TIMEOUT=120

# Maximum messages to process for extraction
MEMORY_EXTRACTION_MAX_MESSAGES=20

# Maximum content length per message
MEMORY_EXTRACTION_MAX_CONTENT_LENGTH=500

# Maximum memories to extract per session
MEMORY_EXTRACTION_MAX_MEMORIES=10

# Directory for storing memories
MEMORY_STORAGE_DIR=.data/memories

# ========================
# SMOKE TEST CONFIGURATION
# ========================

# Model category to use for smoke tests (fast/default/thinking)
SMOKE_TEST_MODEL_CATEGORY=fast

# Skip tests when AI is unavailable instead of failing
SMOKE_TEST_SKIP_ON_AI_UNAVAILABLE=true

# AI evaluation timeout in seconds
SMOKE_TEST_AI_TIMEOUT=30

# Maximum characters to send to AI for evaluation
SMOKE_TEST_MAX_OUTPUT_CHARS=5000

# Test data directory (automatically cleaned up)
SMOKE_TEST_TEST_DATA_DIR=.smoke_test_data
